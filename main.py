import asyncio
import datetime
import json
import traceback
import typing
import os
import yaml
import random
import re
import copy
import shutil
from pkg.platform.sources.aiocqhttp import AiocqhttpAdapter
from pkg.provider import runner
from pkg.core import app
from pkg.core import entities as core_entities
from pkg.platform.types import message as platform_message
from pkg.plugin.context import register, handler, BasePlugin, APIHost, EventContext
from pkg.plugin.events import PersonMessageReceived, GroupMessageReceived, NormalMessageResponded, GroupNormalMessageReceived
from pkg.provider import entities as llm_entities
from plugins.Waifu.cells.config import ConfigManager
from plugins.Waifu.cells.generator import Generator
from plugins.Waifu.cells.cards import Cards
from plugins.Waifu.organs.memories import Memory
from plugins.Waifu.systems.narrator import Narrator
from plugins.Waifu.systems.value_game import ValueGame
from plugins.Waifu.organs.thoughts import Thoughts
from pkg.platform.types.message import MessageChain, Plain, logger


COMMANDS = {
    "åˆ—å‡ºå‘½ä»¤": "åˆ—å‡ºç›®å‰æ”¯æ´æ‰€æœ‰å‘½ä»¤åŠä»‹ç»ï¼Œç”¨æ³•ï¼š[åˆ—å‡ºå‘½ä»¤]ã€‚",
    "å…¨éƒ¨è®°å¿†": "æ˜¾ç¤ºç›®å‰æ‰€æœ‰é•¿çŸ­æœŸè®°å¿†ï¼Œç”¨æ³•ï¼š[å…¨éƒ¨è®°å¿†]ã€‚",
    "ä¼šè¯è®°å¿†":"æ˜¾ç¤ºå½“å‰ä¼šè¯ä½¿ç”¨çš„è®°å¿†ï¼Œç”¨æ³•ï¼š[ä¼šè¯è®°å¿†]ã€‚",
    "æœ€è¿‘è®°å¿†": "æ˜¾ç¤ºæœ€è¿‘çš„é•¿æœŸè®°å¿†ï¼Œç”¨æ³•ï¼š[æœ€è¿‘è®°å¿†]ã€‚",
    "æœ€è¿‘å¬å›": "æ˜¾ç¤ºæœ€è¿‘å¬å›çš„è®°å¿†ï¼Œç”¨æ³•ï¼š[æœ€è¿‘å¬å›]ã€‚",
    "æœ€è¿‘L0å¬å›": "æ˜¾ç¤ºæœ€è¿‘å¬å›çš„è®°å¿†ï¼Œç”¨æ³•ï¼š[æœ€è¿‘L0å¬å›]ã€‚",
    "æœ€è¿‘L1å¬å›": "æ˜¾ç¤ºæœ€è¿‘å¬å›çš„è®°å¿†ï¼Œç”¨æ³•ï¼š[æœ€è¿‘L1å¬å›]ã€‚",
    "æœ€è¿‘L2å¬å›": "æ˜¾ç¤ºæœ€è¿‘å¬å›çš„è®°å¿†ï¼Œç”¨æ³•ï¼š[æœ€è¿‘L2å¬å›]ã€‚",
    "æœ€è¿‘L3å¬å›": "æ˜¾ç¤ºæœ€è¿‘å¬å›çš„è®°å¿†ï¼Œç”¨æ³•ï¼š[æœ€è¿‘L3å¬å›]ã€‚",
    "æœ€è¿‘L4å¬å›": "æ˜¾ç¤ºæœ€è¿‘å¬å›çš„è®°å¿†ï¼Œç”¨æ³•ï¼š[æœ€è¿‘L4å¬å›]ã€‚",
    "æœ€è¿‘L5å¬å›": "æ˜¾ç¤ºæœ€è¿‘å¬å›çš„è®°å¿†ï¼Œç”¨æ³•ï¼š[æœ€è¿‘L5å¬å›]ã€‚",
    "å¬å›é˜ˆå€¼": "æ˜¾ç¤ºå¬å›é˜ˆå€¼ï¼Œç”¨æ³•ï¼š[å¬å›é˜ˆå€¼]ã€‚",
    "åˆ é™¤è®°å¿†": "åˆ é™¤æ‰€æœ‰é•¿çŸ­æœŸè®°å¿†ï¼Œç”¨æ³•ï¼š[åˆ é™¤è®°å¿†]ã€‚",
    "ä¿®æ”¹æ•°å€¼": "ä¿®æ”¹Value Gameçš„æ•°å­—ï¼Œç”¨æ³•ï¼š[ä¿®æ”¹æ•°å€¼][æ•°å€¼]ã€‚",
    "æ€åº¦": "æ˜¾ç¤ºå½“å‰Value Gameæ‰€å¯¹åº”çš„â€œæ€åº¦Mannerâ€ï¼Œç”¨æ³•ï¼š[æ€åº¦]ã€‚",
    "åŠ è½½é…ç½®": "é‡æ–°åŠ è½½æ‰€æœ‰é…ç½®æ–‡ä»¶ï¼ˆä»…Waifuï¼‰ï¼Œç”¨æ³•ï¼š[åŠ è½½é…ç½®]ã€‚",
    "åœæ­¢æ´»åŠ¨": "åœæ­¢æ—ç™½è®¡æ—¶å™¨ï¼Œç”¨æ³•ï¼š[åœæ­¢æ´»åŠ¨]ã€‚",
    "å¼€åœºåœºæ™¯": "ä¸»åŠ¨è§¦å‘æ—ç™½è¾“å‡ºè§’è‰²å¡ä¸­çš„â€œå¼€åœºåœºæ™¯Prologueâ€ï¼Œç”¨æ³•ï¼š[å¼€åœºåœºæ™¯]ã€‚",
    "æ—ç™½": "ä¸»åŠ¨è§¦å‘æ—ç™½æ¨è¿›å‰§æƒ…ï¼Œç”¨æ³•ï¼š[æ—ç™½]ã€‚",
    "ç»§ç»­": "ä¸»åŠ¨è§¦å‘Botç»§ç»­å›å¤æ¨è¿›å‰§æƒ…ï¼Œç”¨æ³•ï¼š[ç»§ç»­]ã€‚",
    "æ§åˆ¶äººç‰©": "æ§åˆ¶è§’è‰²å‘è¨€ï¼ˆè¡ŒåŠ¨ï¼‰æˆ–è§¦å‘AIç”Ÿæˆè§’è‰²æ¶ˆæ¯ï¼Œç”¨æ³•ï¼š[æ§åˆ¶äººç‰©][è§’è‰²åç§°/assistant]|[å‘è¨€(è¡ŒåŠ¨)/ç»§ç»­]ã€‚",
    "æ¨è¿›å‰§æƒ…": "è‡ªåŠ¨ä¾åºè°ƒç”¨ï¼šæ—ç™½ -> æ§åˆ¶äººç‰©ï¼Œè§’è‰²åç§°çœç•¥é»˜è®¤ä¸ºuserï¼Œç”¨æ³•ï¼š[æ¨è¿›å‰§æƒ…][è§’è‰²åç§°]ã€‚",
    "æ’¤å›": "ä»çŸ­æœŸè®°å¿†ä¸­åˆ é™¤æœ€åçš„å¯¹è¯ï¼Œç”¨æ³•ï¼š[æ’¤å›]ã€‚",
    "è¯·è®¾è®¡": "è°ƒè¯•ï¼šè®¾è®¡ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨æ³•ï¼š[è¯·è®¾è®¡][è®¾è®¡å†…å®¹]ã€‚",
    "è¯·é€‰æ‹©": "è°ƒè¯•ï¼šä»ç»™å®šåˆ—è¡¨ä¸­é€‰æ‹©ï¼Œç”¨æ³•ï¼š[è¯·é€‰æ‹©][é—®é¢˜]|[é€‰é¡¹1,é€‰é¡¹2,â€¦â€¦]ã€‚",
    "å›ç­”æ•°å­—": "è°ƒè¯•ï¼šè¿”å›æ•°å­—ç­”æ¡ˆï¼Œç”¨æ³•ï¼š[å›ç­”æ•°å­—][é—®é¢˜]ã€‚",
    "å›ç­”é—®é¢˜": "è°ƒè¯•ï¼šå¯è‡ªå®šç³»ç»Ÿæç¤ºçš„é—®ç­”æ¨¡å¼ï¼Œç”¨æ³•ï¼š[å›ç­”é—®é¢˜][ç³»ç»Ÿæç¤ºè¯­]|[ç”¨æˆ·æç¤ºè¯­] / [å›ç­”é—®é¢˜][ç”¨æˆ·æç¤ºè¯­]ã€‚",
}


class WaifuCache:

    ap: app.Application

    def __init__(self, ap: app.Application, launcher_id: str, launcher_type: str):
        self.launcher_id = launcher_id
        self.launcher_type = launcher_type
        self.langbot_group_rule = False
        self.memory = Memory(ap, launcher_id, launcher_type)
        self.value_game = ValueGame(ap)
        self.cards = Cards(ap)
        self.narrator = Narrator(ap, launcher_id)
        self.thoughts = Thoughts(ap)
        self.conversation_analysis_flag = True
        self.thinking_mode_flag = True
        self.story_mode_flag = True
        self.display_thinking = True
        self.display_value = True
        self.response_rate = 0.7
        self.narrate_intervals = []
        self.launcher_timer_tasks = None
        self.unreplied_count = 0
        self.continued_rate = 0.2
        self.continued_count = 0
        self.continued_max_count = 2
        self.summarization_mode = True
        self.personate_mode = True
        self.jail_break_mode = "off"
        self.response_timers_flag = False
        self.bracket_rate = []
        self.group_response_delay = 3
        self.person_response_delay = 0
        self.personate_delay = 0
        self.group_message_chain = None
        self.blacklist = []
        self.ignore_prefix = []

        self.proactive_greeting_enabled: bool = False
        self.proactive_greeting_probability: int = 0
        self.proactive_min_inactive_hours = 3.0
        self.proactive_do_not_disturb_start = "23:00"
        self.proactive_do_not_disturb_end = "8:00"
       # self.target_user_id = ""




@runner.runner_class("waifu-mode")
class WaifuRunner(runner.RequestRunner):
    async def run(self, query: core_entities.Query):
        # ä¸ºäº†é€‚é…å…¶ä»–æ’ä»¶ï¼Œä»¥å±è”½runnerçš„æ–¹å¼å–ä»£ctx.prevent_default()
        # ä¸éœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æ‰‹åŠ¨é…ç½®è¿è¡Œå™¨ï¼Œå°†åœ¨æ’ä»¶åŠ è½½è¿‡ç¨‹å¼ºåˆ¶æŒ‡å®šä¸ºwaifu-mode
        # è¿”å›ä¸€ä¸ªç©ºçš„å¼‚æ­¥ç”Ÿæˆå™¨
        if False:  # æ°¸è¿œä¸ä¼šæ‰§è¡Œï¼Œä½†ä¿ç•™ç”Ÿæˆå™¨è¯­æ³•
            yield
        return

@register(name="Waifu", description="Cuter than real waifu!", version="1.9.8", author="ElvisChenML")
class WaifuPlugin(BasePlugin):
    def __init__(self, host: APIHost):


        super().__init__(host)
      #  self.proactive_check_interval_seconds = 60 # æµ‹è¯•å¾ªç¯é—´éš”
        self.ap = host.ap
        self._ensure_required_files_exist()
        self._generator = Generator(self.ap)
        self.waifu_cache: typing.Dict[str, WaifuCache] = {}
        self._set_permissions_recursively("data/plugins/Waifu/", 0o777)

        enabled_adapters = self.host.get_platform_adapters()

        #self.first_adapter = enabled_adapters[0]


        for adapter in enabled_adapters:
            if isinstance(adapter, AiocqhttpAdapter): # é€‰æ‹©qqé€‚é…å™¨
                self.first_adapter = adapter
                self.ap.logger.info(f"è·å–åˆ°qqapdater :{self.first_adapter}")
                break
            else:
                self.ap.logger.error(f"Can't find apdater for qq!!")

        print("WaifuPlugin: __init__ completed.")



    async def initialize(self):  #é‡å†™åˆå§‹åŒ–
        await super().initialize()

        #åˆå§‹åŒ– Generator çš„æ¨¡å‹é…ç½® ---
        if hasattr(self, '_generator') and hasattr(self._generator, '_initialize_model_config'):
            self.ap.logger.info("WaifuPlugin: Initializing Generator's model configuration...")
            try:
                await self._generator._initialize_model_config()  # ä¸»åŠ¨è°ƒç”¨åˆå§‹åŒ–æ–¹æ³•
                if self._generator.selected_model_info:
                    self.generator_model_ready = True
                    self.ap.logger.info(
                        f"WaifuPlugin: Generator model selected: {self._generator.selected_model_info.model_entity.name}")
            except Exception as e:
                self.ap.logger.error(f"WaifuPlugin: Error during Generator model initialization: {e}")
                self.ap.logger.error(traceback.format_exc())
        else:
            self.ap.logger.error("WaifuPlugin: _generator or _generator._initialize_model_config not found!")


        global_config = "data/plugins/Waifu/config/waifu.yaml"
        self.target_qq = self._load_target_qq_from_global_config_file(global_config)  #åœ¨plugins/Waifu/templates/waifu.yaml è¯»å–qqå·
        print(self.target_qq)

        asyncio.create_task(self._proactive_loop())   #åˆ›å»ºæ£€æµ‹ç”¨æˆ·æ´»è·ƒä»»åŠ¡
        self.ap.logger.info(f"start to proactive_loop")





    ##è¯»å–tagå’Œsummary
    def _get_tag_summary(self):

        try:
            fixed_file_path = f"data/plugins/Waifu/data/memories_{self.target_qq}.json"
            print(f"Attempting to read LTM file: {fixed_file_path}")
        except Exception as e:
            print(f"ERROR: Attribute 'target_qq' not found on self: {e}\\n")
            return None, None


        try:
            with open(fixed_file_path, "r", encoding="utf-8") as file:
                data = json.load(file)  # è§£ææ•´ä¸ªJSONæ•°æ®

            if "long_term" in data and isinstance(data["long_term"], list) and data["long_term"]:
                latest_entry = data["long_term"][-1]  # è·å–åˆ—è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´ 
                print(f"latest_entry:{latest_entry}")

                if isinstance(latest_entry, dict) and "summary" in latest_entry and "tags" in latest_entry:
                    summary_text = latest_entry["summary"]
                    tags_list = latest_entry["tags"]

                    processed_summary = summary_text   ## ----å¤„ç†summary_text
                    status_tracking_marker = "çŠ¶æ€è¿½è¸ªï¼š"
                    important_affairs_marker = "é‡è¦äº‹åŠ¡ï¼š"
                    status_tracking_start_index = summary_text.find(status_tracking_marker)

                    if status_tracking_start_index != -1:
                        narrative_part = summary_text[:status_tracking_start_index].strip()
                        important_affairs_start_index = summary_text.find(important_affairs_marker,
                                                                          status_tracking_start_index)
                        if important_affairs_start_index != -1:
                            # æå– "é‡è¦äº‹åŠ¡ï¼š" ä¹‹åçš„å†…å®¹
                            important_affairs_content = summary_text[important_affairs_start_index + len(
                                important_affairs_marker):].strip()   # å»æ‰å¤šä½™çš„æ¢è¡Œ
                            lines = [line.strip() for line in important_affairs_content.split('\n') if line.strip()]
                            important_affairs_part_extracted = "\næˆ‘ä»¬ä¹‹å‰æåˆ°çš„ä¸€äº›é‡è¦äº‹æƒ…æœ‰ï¼š" + "\n    ".join(
                                lines[:3])  # å‰3ä¸ªäº‹åŠ¡
                            processed_summary = f"{narrative_part}{important_affairs_part_extracted}"
                        else:
                            processed_summary = narrative_part  # åªç”¨å™äº‹éƒ¨åˆ†
                    else:
                        print(
                            "DEBUG LTM Processed: 'çŠ¶æ€è¿½è¸ªï¼š' marker not found. Using summary as is (or potentially truncated).")
                    return processed_summary, tags_list    #è¿”å›tagå’Œsummary
                else:
                    print("ERROR: Latest LTM entry has unexpected format or missing 'summary'/'tags'.")
                    return None, None
            else:
                print("ERROR: No 'long_term' list found in the JSON data, or it is empty.")
                return None, None
        except FileNotFoundError:
            print(f"ERROR: File not found at path: {fixed_file_path}")
            return None, None
        except json.JSONDecodeError as e:
            print(f"ERROR: Could not decode JSON from file. Error: {e}")
            return None, None
        except Exception as e:
            print(f"ERROR: An unexpected error occurred: {e}")
            traceback.print_exc()
            return None, None



    # async def _get_target_adapter_for_test(self): #è·å–æœºå™¨äººå®ä¾‹
    #     if not hasattr(self.host, 'get_platform_adapters'):
    #         print("WaifuPlugin Test ERROR: self.host has no 'get_platform_adapters' method.")
    #         return None
    #

    #    # platform_manager = self.ap.platform_mgr

    #    # runtime_bot = await platform_manager.get_bot_by_uuid(self.test_target_bot_uuid)
    #   #  return runtime_bot.adapter




    async def proactive_greeting(self):   ##ä¸»åŠ¨é—®å€™ç”Ÿæˆè¯

        summary_text, tags_list =  self._get_tag_summary()  #è·å–tagå’Œsummary
        #filtered_tags = [tag for tag in tags_list if not tag.startswith("PADDING:") and not tag.startswith("DATETIME:")] # ç®€å•ç­›é€‰ tags

        await self._load_config(self.target_qq, "person")
        config = self.waifu_cache[self.target_qq]

        raw_prompt = config.cards.generate_system_prompt()   #è·å–è§’è‰²å¡
        full_card_prompt_text = config.memory.to_custom_names(raw_prompt)

        system_prompt_for_summarizing_card = (
            f"è¯·é˜…è¯»è¿™å¼ è§’è‰²å¡ï¼Œå¹¶ä»ä¸­æå–å‡ºæœ€èƒ½ä»£è¡¨è¯¥è§’è‰²æ ¸å¿ƒæ€§æ ¼ã€è¡Œä¸ºæ–¹å¼å…³é”®è¦ç‚¹ã€‚"
            f"æ€»ç»“åº”éå¸¸ç®€çŸ­ç²¾ç‚¼\n"
            f"è¯·ç›´æ¥è¾“å‡ºå¤§æ¦‚ä¸€å¥è¯çš„æ–‡æœ¬æ‘˜è¦\n"
        )
        if self._generator and self._generator.selected_model_info:
            try:
                if hasattr(self._generator, 'set_speakers'):
                    self._generator.set_speakers([])  # æ¸…ç©ºæˆ–ä¸è®¾ç½®ç‰¹å®šspeaker
                card_summary_text = await self._generator.return_chat(
                    request=full_card_prompt_text,
                    system_prompt=system_prompt_for_summarizing_card  # æŒ‡ç¤ºLLMè¿›è¡Œæ€»ç»“çš„ç³»ç»Ÿæç¤º
                )

            except Exception as e:
                print(f"ERROR during LLM call for card summary: {e}")
        else:
            print("ERROR: Generator or its model is not ready for card summary call.")

        conversations = config.memory.get_normalize_short_term_memory()
        conversation = conversations[-5:]  #è·å–å†å²å¯¹è¯åˆ‡ç‰‡
        formatted_history_lines = []
        for msg_obj in conversation:
            content_text = str(msg_obj.content).strip()
            formatted_history_lines.append(f"\n{content_text}")

        if formatted_history_lines:
            recent_dialogue_str = "\n".join(formatted_history_lines)   #ç®€å•å¤„ç†å¯¹è¯

        summary_snippet = summary_text[:150] + "..." if len(summary_text) > 150 else summary_text  # å– summary çš„å‰ä¸€éƒ¨åˆ†ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œé¿å…è¿‡é•¿
        system_prompt_with_ltm = (
            f"ä½ çš„è§’è‰²è®¾å®šæ˜¯è¿™æ ·çš„:'{card_summary_text}\n'"
           # f"å¯¹æ–¹å¯èƒ½æœ‰ä¸€æ®µæ—¶é—´æ²¡æœ‰è¯´è¯äº†ã€‚"
            f"æˆ‘ä»¬æœ€è¿‘çš„å¯¹è¯ä¸­ï¼Œæœ‰ä¸€ä¸ªæ€»ç»“å¤§è‡´æ˜¯è¿™æ ·çš„ï¼š'{summary_snippet}'\n"
         #   f"å¹¶ä¸”æ¶‰åŠåˆ°çš„ä¸€äº›è¯é¢˜æ ‡ç­¾æœ‰ï¼š'{filtered_tags}'ã€‚\n"  
            f"ä½œä¸ºå‚è€ƒï¼Œä»¥ä¸‹æ˜¯æˆ‘ä»¬æœ€è¿‘çš„ä¸€äº›å¯¹è¯å†…å®¹ï¼š[å¯¹è¯å¼€å§‹\n{recent_dialogue_str}\nå¯¹è¯ç»“æŸ]\n\n" 
            f"è¯·ä½ åŸºäºè¿™äº›ä¿¡æ¯ï¼Œè‡ªç„¶åœ°å¯¹ä»–å‘èµ·ä¸€ä¸ªä¸»åŠ¨çš„é—®å€™æˆ–å¯¹è¯ã€‚"
            f"è¯·ç›´æ¥è¯´å‡ºéå¸¸ç®€çŸ­çš„é—®å€™å†…å®¹ï¼Œå¤§çº¦ä¸€å¥è¯ï¼Œç®€çŸ­ç²¾ç‚¼ï¼Œä¸è¦å¸¦ä¸Šä½ çš„åå­—ä½œä¸ºå‰ç¼€ã€‚"
        )
        user_request_for_greeting = " "
        response = await self._generator.return_chat(
            request=user_request_for_greeting,
            system_prompt=system_prompt_with_ltm
        )
        await config.memory.save_memory(role="assistant", content=response)  #ä¸»åŠ¨å‘è¨€å­˜å…¥åˆ°å†å²è®°å¿†å½“ä¸­
        return response  #è¿”å›LLM å›åº”


    async def proactive_send(self):  #ä¸»åŠ¨å‘é€æ¶ˆæ¯åŠŸèƒ½
        try:
            #adapter_instance = await self._get_target_adapter_for_test()
            adapter_instance = self.first_adapter   #è·å–é€‚é…å™¨

            if adapter_instance:
                message_to_send_str = await self.proactive_greeting()  #è¿”å›message
                print(f"wait to send{self.target_qq}\n")

                await adapter_instance.send_message(
                    target_type="person",
                    target_id=self.target_qq,
                    message=platform_message.MessageChain([message_to_send_str])
                )
            else:
                print("ERROR: Could not get adapter instance for proactive send.")

        except Exception as e:
            print(f"ERROR during proactive send: {e}")
            traceback.print_exc()
        print("proactive_send() task completed.")


    async def _check_user_inactivity(self):  #æ£€æµ‹ç”¨æˆ·æ´»è·ƒæ—¶é•¿

        await self._load_config(self.target_qq, "person")  # è¯»å–é…ç½®
        config = self.waifu_cache[self.target_qq]
        current_time = datetime.datetime.now()
        last_message_time = config.memory.get_lastest_time(config.memory.short_term_memory)  #æ—¶é—´å·®å€¼
        if not last_message_time:
            print(f"Could not extract last message time for user")
            return

        time_difference = current_time - last_message_time
        inactive_minutes = time_difference.total_seconds()
        inactive_minutes_float = float(inactive_minutes) / 60

        inactivity_threshold_minutes = config.proactive_min_inactive_hours
        inactivity_threshold_minutes_float = float(inactivity_threshold_minutes) * 60

        print(inactive_minutes_float)
        print(inactivity_threshold_minutes_float)

        if inactive_minutes_float > inactivity_threshold_minutes_float:  #å·®å€¼å¤§äºè§„å®šæœ€å°æ—¶é—´

            current_time_hm_only = current_time.time()
            proactive_do_not_disturb_start = config.proactive_do_not_disturb_start
            proactive_do_not_disturb_end = config.proactive_do_not_disturb_end
            time_format = "%H:%M"
            dnd_start_time_obj = datetime.datetime.strptime(proactive_do_not_disturb_start, time_format).time()
            dnd_end_time_obj = datetime.datetime.strptime(proactive_do_not_disturb_end, time_format).time()

            is_currently_do_not_disturb = False
            print(
                f"Check: Current time: {current_time_hm_only.strftime(time_format)}, Period: {proactive_do_not_disturb_start} - {proactive_do_not_disturb_end}")
            if dnd_start_time_obj > dnd_end_time_obj:  # è·¨å¤œ
                if current_time_hm_only >= dnd_start_time_obj or current_time_hm_only < dnd_end_time_obj:
                    is_currently_do_not_disturb = True
            else:  # ä¸è·¨å¤œ
                if dnd_start_time_obj <= current_time_hm_only < dnd_end_time_obj:
                    is_currently_do_not_disturb = True
            if is_currently_do_not_disturb:
                print(
                    f"å‹¿æ‰°æ—¶é—´")
            else:
                print(f"botå¼€å§‹ä¸»åŠ¨å‘é€æ¶ˆæ¯!")
                asyncio.create_task(self.proactive_send())  #ä¸»åŠ¨å‘æ¶ˆæ¯
        else:
            print(f"ERROR Inactivity: Could not send greeting ")
            return


    async def _proactive_loop(self):
        print("!!_proactive_loop:!!\n")
        if not self.target_qq:  # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½
            print("ERROR:self.target_qq is not configured correctly. .\n")
            self.ap.logger.error("self.target_qq is invalid..\n")
            return # ç›´æ¥é€€å‡ºå¾ªç¯ä»»åŠ¡

        await self._load_config(self.target_qq, "person")  # è¯»å–é…ç½®


        config = self.waifu_cache[self.target_qq]
        self.ap.logger.info(f"proactive_mode : {config.proactive_greeting_enabled} ")
        self.ap.logger.info(f"summarization_mode : {config.summarization_mode} ")

        if config.proactive_greeting_enabled and config.summarization_mode:
            self.ap.logger.info(
                f"WaifuPlugin: Proactive loop started.")
            initial_loop_delay = 30  # å†·å¯åŠ¨

            try:
                await asyncio.sleep(initial_loop_delay)
            except asyncio.CancelledError:
                self.ap.logger.info("WaifuPlugin:cancelled during initial delay.")
                return

            while True:  #å¾ªç¯æ£€æµ‹ç”¨æˆ·çŠ¶æ€
                self.ap.logger.info(f"WaifuPlugin Loop: Running inactivity check for user {self.target_qq}...")
                try:
                    probability_to_greet = config.proactive_greeting_probability
                    self.ap.logger.info(
                        f"probability:{probability_to_greet}")
                    if random.randint(1, 100) <= probability_to_greet:  #å‡ ç‡
                        await self._check_user_inactivity()  #è¿›å…¥æ£€æµ‹ç”¨æˆ·æ´»è·ƒæ—¶é—´


                except asyncio.CancelledError:
                    self.ap.logger.info("WaifuPlugin: Proactive loop cancelled during check/greet.")
                    break
                except Exception as e_loop:
                    self.ap.logger.error(f"WaifuPlugin ERROR in proactive greeting loop: {e_loop}")
                    traceback.print_exc()  # æ‰“å°é”™è¯¯

                loop_time = 1800  #æ¯ä¸‰ååˆ†é’Ÿè¿›è¡Œä¸€æ¬¡æ£€æŸ¥

                self.ap.logger.info(f"WaifuPlugin Loop: Check finished. Sleeping for {loop_time} seconds...")

                try:
                    await asyncio.sleep(loop_time)
                except asyncio.CancelledError:
                    self.ap.logger.info("WaifuPlugin: Proactive greeting loop cancelled during sleep.")
                    break  # é€€å‡ºå¾ªç¯

#---------


    async def destroy(self):
        self.ap.logger.warning("Waifuæ’ä»¶æ­£åœ¨é€€å‡º....")
    # @handler(NormalMessageResponded)
    # async def normal_message_responded(self, ctx: EventContext):
    #     self.ap.logger.info(f"LangGPTçš„NormalMessageResponded: {str(ctx.event.response_text)}ã€‚")

    async def _access_control_check(self, ctx: EventContext) -> bool:
        """
        è®¿é—®æ§åˆ¶æ£€æŸ¥ï¼Œæ ¹æ®é…ç½®åˆ¤æ–­æ˜¯å¦å…è®¸ç»§ç»­å¤„ç†
        :param ctx: åŒ…å«äº‹ä»¶ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ EventContext å¯¹è±¡
        :return: True if allowed to continue, False otherwise
        """
        bot_account_id = ctx.event.query.adapter.bot_account_id
        text_message = str(ctx.event.query.message_chain)
        launcher_id = ctx.event.launcher_id
        sender_id = ctx.event.sender_id
        launcher_type = ctx.event.launcher_type
        event_type = "PMR"
        if isinstance(ctx.event, GroupNormalMessageReceived):
            event_type = "GNMR"
        elif isinstance(ctx.event, GroupMessageReceived):
            event_type = "GMR"

        # é»‘ç™½åå•æ£€æŸ¥
        mode = self.ap.instance_config.data.get("pipeline", {}).get("access-control", {}).get("mode")
        sess_list = set(self.ap.instance_config.data.get("pipeline", {}).get("access-control", {}).get(mode, []))

        found = (launcher_type == "group" and "group_*" in sess_list) or (launcher_type == "person" and "person_*" in sess_list) or f"{launcher_type}_{launcher_id}" in sess_list

        if (mode == "whitelist" and not found) or (mode == "blacklist" and found):
            reason = "ä¸åœ¨ç™½åå•ä¸­" if mode == "whitelist" else "åœ¨é»‘åå•ä¸­"
            self.ap.logger.info(f"æ‹’ç»è®¿é—®: {launcher_type}_{launcher_id} {reason}ã€‚")
            return False

        # æ£€æŸ¥é…ç½®æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨åˆ™åŠ è½½é…ç½®
        if launcher_id not in self.waifu_cache:
            await self._load_config(launcher_id, ctx.event.launcher_type)
        waifu_data = self.waifu_cache.get(launcher_id, None)
        if waifu_data:
            waifu_data.memory.bot_account_id = bot_account_id
        # ç»§æ‰¿LangBotçš„ç¾¤æ¶ˆæ¯å“åº”è§„åˆ™æ—¶å¿½ç•¥ GroupMessageReceived ä¿¡å·
        if event_type == "GMR" and waifu_data.langbot_group_rule == True:
            return False
        # ä»…ç”±Waifuç®¡ç†ç¾¤èŠå“åº”è§„åˆ™æ—¶å¿½ç•¥ GroupNormalMessageReceived ä¿¡å·
        if event_type == "GNMR" and waifu_data.langbot_group_rule == False:
            return False

        # æ’é™¤ä¸»é¡¹ç›®å‘½ä»¤
        cmd_prefix = self.ap.instance_config.data.get("command", {}).get("command-prefix", [])
        if any(text_message.startswith(prefix) for prefix in cmd_prefix):
            return False

        # æ’é™¤ç‰¹å®šå‰ç¼€
        if waifu_data and any(text_message.startswith(prefix) for prefix in waifu_data.ignore_prefix):
            return False

        # Waifu ç¾¤èŠæˆå‘˜é»‘åå•
        if waifu_data and sender_id in waifu_data.blacklist:
            self.ap.logger.info(f"å·²å±è”½é»‘åå•ä¸­{sender_id}çš„å‘è¨€: {str(text_message)}ã€‚")
            return False

        return True

    @handler(PersonMessageReceived)
    async def person_message_received(self, ctx: EventContext):
        if not await self._access_control_check(ctx):
            return

        need_assistant_reply, need_save_memory = await self._handle_command(ctx)
        if need_assistant_reply:
            await self._request_person_reply(ctx, need_save_memory)
            asyncio.create_task(self._handle_narration(ctx, ctx.event.launcher_id))
            ctx.prevent_default()  # é˜»æ­¢ LangBot çš„é»˜è®¤å›å¤è¡Œä¸º

    @handler(GroupMessageReceived)
    @handler(GroupNormalMessageReceived)
    async def group_message_received(self, ctx: EventContext):
        if not await self._access_control_check(ctx):
            return

        # åœ¨GroupNormalMessageReceivedçš„ctx.event.query.message_chainä¼šå°†Atç§»é™¤
        # æ‰€ä»¥è¿™åœ¨ç»è¿‡ä¸»é¡¹ç›®å¤„ç†å‰å…ˆè¿›è¡Œå¤‡ä»½
        self.waifu_cache[ctx.event.launcher_id].group_message_chain = copy.deepcopy(ctx.event.query.message_chain)

        need_assistant_reply, _ = await self._handle_command(ctx)
        if need_assistant_reply:
            await self._request_group_reply(ctx)
            ctx.prevent_default()  # é˜»æ­¢ LangBot çš„é»˜è®¤å›å¤è¡Œä¸º

    async def _load_config(self, launcher_id: str, launcher_type: str):    ##åŠ è½½é…ç½®
        self.waifu_cache[launcher_id] = WaifuCache(self.ap, launcher_id, launcher_type)
        cache = self.waifu_cache[launcher_id]

        config_mgr = ConfigManager(f"data/plugins/Waifu/config/waifu", "plugins/Waifu/templates/waifu", launcher_id) #è¯»å–ç”¨æˆ·é…ç½®
        await config_mgr.load_config(completion=True)

        character = config_mgr.data.get("character", f"default")
        if character == "default":  # åŒºåˆ†ç§èŠå’Œç¾¤èŠçš„æ¨¡æ¿
            character = f"default_{launcher_type}"
        else:
            character = character.replace(".yaml", "")

        cache.narrate_intervals = config_mgr.data.get("intervals", [])
        cache.story_mode_flag = config_mgr.data.get("story_mode", True)
        cache.thinking_mode_flag = config_mgr.data.get("thinking_mode", True)
        cache.conversation_analysis_flag = config_mgr.data.get("conversation_analysis", True)
        cache.display_thinking = config_mgr.data.get("display_thinking", True)
        cache.display_value = config_mgr.data.get("display_value", False)
        cache.response_rate = config_mgr.data.get("response_rate", 0.7)
        cache.summarization_mode = config_mgr.data.get("summarization_mode", False)
        cache.personate_mode = config_mgr.data.get("personate_mode", True)
        cache.jail_break_mode = config_mgr.data.get("jail_break_mode", "off")
        cache.bracket_rate = config_mgr.data.get("bracket_rate", [])
        cache.group_response_delay = config_mgr.data.get("group_response_delay", 10)
        cache.person_response_delay = config_mgr.data.get("person_response_delay", 0)
        cache.personate_delay = config_mgr.data.get("personate_delay", 0)
        cache.continued_rate = config_mgr.data.get("continued_rate", 0.5)
        cache.continued_max_count = config_mgr.data.get("continued_max_count", 2)
        cache.blacklist = config_mgr.data.get("blacklist", [])
        cache.langbot_group_rule = config_mgr.data.get("langbot_group_rule", False)
        cache.ignore_prefix = config_mgr.data.get("ignore_prefix", [])

        cache.proactive_greeting_enabled = config_mgr.data.get("proactive_greeting_enabled", False)
        cache.proactive_greeting_probability = config_mgr.data.get("proactive_greeting_probability", 0)
        cache.proactive_min_inactive_hours = config_mgr.data.get("proactive_min_inactive_hours", 3.0)
        cache.proactive_max_inactive_hours = config_mgr.data.get("proactive_max_inactive_hours", 4.0)
        if cache.proactive_max_inactive_hours < cache.proactive_min_inactive_hours:
            cache.proactive_max_inactive_hours = cache.proactive_min_inactive_hours

        cache.proactive_do_not_disturb_start = config_mgr.data.get("proactive_do_not_disturb_start","23:00")
        cache.proactive_do_not_disturb_end = config_mgr.data.get("proactive_do_not_disturb_end","08:00")
     #   cache.target_user_id = config_mgr.data.get("target_user_id","")


        await cache.memory.load_config(character, launcher_id, launcher_type)
        await cache.value_game.load_config(character, launcher_id, launcher_type)
        await cache.cards.load_config(character, launcher_type)
        await cache.narrator.load_config()

        self._set_jail_break(cache, "off")
        if cache.jail_break_mode in ["before", "after", "end", "all"]:
            self._set_jail_break(cache, cache.jail_break_mode)

        self._set_permissions_recursively("data/plugins/Waifu/", 0o777)

    async def _handle_command(self, ctx: EventContext) -> typing.Tuple[bool, bool]:
        need_assistant_reply = False
        need_save_memory = False
        response = ""
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]
        msg = str(ctx.event.query.message_chain)
        self.ap.logger.info(f"Waifuå¤„ç†æ¶ˆæ¯:{msg}")

        if msg.startswith("è¯·è®¾è®¡"):
            content = msg[3:].strip()
            response = await self._generator.return_list(content)
        elif msg.startswith("è¯·é€‰æ‹©"):
            content = msg[3:].strip()
            parts = content.split("|")
            if len(parts) == 2:
                question = parts[0].strip()
                options = [opt.strip() for opt in parts[1].split(",")]
                response = await self._generator.select_from_list(question, options)
        elif msg.startswith("å›ç­”æ•°å­—"):
            content = msg[4:].strip()
            response = await self._generator.return_number(content)
        elif msg.startswith("å›ç­”é—®é¢˜"):
            content = msg[4:].strip()
            parts = content.split("|")
            system_prompt = None
            if len(parts) == 2:
                system_prompt = parts[0].strip()
                user_prompt = parts[1].strip()
            else:
                user_prompt = content
            response = await self._generator.return_string(user_prompt, [], system_prompt)
        elif msg == "å…¨éƒ¨è®°å¿†":
            response = config.memory.get_all_memories()
        elif msg == "ä¼šè¯è®°å¿†":
            response = config.memory.get_memories_session()
        elif msg == "æœ€è¿‘è®°å¿†":
            response = config.memory.get_latest_memory()
        elif msg == "æœ€è¿‘å¬å›":
            response = config.memory.get_last_recall_memories()
        elif msg == "æœ€è¿‘L0å¬å›":
            response = config.memory.get_last_l0_recall_memories()
        elif msg == "æœ€è¿‘L1å¬å›":
            response = config.memory.get_last_l1_recall_memories()
        elif msg == "æœ€è¿‘L2å¬å›":
            response = config.memory.get_last_l2_recall_memories()
        elif msg == "æœ€è¿‘L3å¬å›":
            response = config.memory.get_last_l3_recall_memories()
        elif msg == "æœ€è¿‘L4å¬å›":
            response = config.memory.get_last_l4_recall_memories()
        elif msg == "æœ€è¿‘L5å¬å›":
            response = config.memory.get_last_l5_recall_memories()
        elif msg == "å¬å›é˜ˆå€¼":
            response = config.memory.format_thresholds()
        elif msg == "åˆ é™¤è®°å¿†":
            response = self._stop_timer(launcher_id)
            config.memory.delete_local_files()
            config.value_game.reset_value()
            response += "è®°å¿†å·²åˆ é™¤ã€‚"
        elif msg.startswith("ä¿®æ”¹æ•°å€¼"):
            value = int(msg[4:].strip())
            config.value_game.change_manner_value(value)
            response = f"æ•°å€¼å·²æ”¹å˜ï¼š{value}"
        elif msg == "æ€åº¦":
            manner = config.value_game.get_manner_description()
            if manner:
                response = f"ğŸ’•å€¼ï¼š{config.value_game.get_value()}\næ€åº¦ï¼š{manner}"
            else:
                response = f"é”™è¯¯ï¼šæœªæ­£ç¡®è®¾å®šæ€åº¦å€¼ç›¸å…³é…ç½®"
        elif msg == "åŠ è½½é…ç½®":
            launcher_type = ctx.event.launcher_type
            await self._load_config(launcher_id, launcher_type)
            response = "é…ç½®å·²é‡è½½"
        elif msg == "åœæ­¢æ´»åŠ¨":
            response = self._stop_timer(launcher_id)
        elif msg == "å¼€åœºåœºæ™¯":
            response = config.memory.to_custom_names(config.cards.get_prologue())
            ctx.event.query.message_chain = platform_message.MessageChain([f"æ§åˆ¶äººç‰©narrator|{response}"])
            need_assistant_reply, need_save_memory = await self._handle_command(ctx)
        elif msg == "æ—ç™½":
            await self._narrate(ctx, launcher_id)
        elif msg == "ç»§ç»­":
            await self._continue_person_reply(ctx)
        elif msg.startswith("æ§åˆ¶äººç‰©"):
            content = msg[4:].strip()
            parts = content.split("|")
            if len(parts) == 2:
                role = parts[0].strip()
                if role.lower() == "user":
                    role = config.memory.user_name
                prompt = parts[1].strip()
                if prompt == "ç»§ç»­":
                    user_prompt = await config.thoughts.generate_character_prompt(config.memory, config.cards, role)
                    if user_prompt:  # è‡ªåŠ¨ç”Ÿæˆè§’è‰²å‘è¨€
                        self._generator.set_speakers([role])
                        prompt = await self._generator.return_chat(user_prompt)
                        response = f"{role}ï¼š{prompt}"
                        await config.memory.save_memory(role=role, content=prompt)
                        need_assistant_reply = True
                    else:
                        response = f"é”™è¯¯ï¼šè¯¥å‘½ä»¤ä¸æ”¯æ´çš„è¯¥è§’è‰²"
                else:  # äººå·¥æŒ‡å®šè§’è‰²å‘è¨€
                    await config.memory.save_memory(role=role, content=prompt)
                    need_assistant_reply = True
        elif msg.startswith("æ¨è¿›å‰§æƒ…"):
            role = msg[4:].strip()
            if not role:  # è‹¥ä¸æŒ‡å®šå“ªä¸ªè§’è‰²æ¨è¿›å‰§æƒ…ï¼Œé»˜è®¤ä¸ºuser
                role = "user"
            ctx.event.query.message_chain = platform_message.MessageChain(["æ—ç™½"])
            need_assistant_reply, need_save_memory = await self._handle_command(ctx)  # æ­¤æ—¶ä¸ä¼šè§¦å‘assistantå›å¤
            ctx.event.query.message_chain = platform_message.MessageChain([f"æ§åˆ¶äººç‰©{role}|ç»§ç»­"])
            need_assistant_reply, need_save_memory = await self._handle_command(ctx)
        elif msg.startswith("åŠŸèƒ½æµ‹è¯•"):
            # éšè—æŒ‡ä»¤ï¼ŒåŠŸèƒ½æµ‹è¯•ä¼šæ¸…ç©ºè®°å¿†ï¼Œè¯·è°¨æ…æ‰§è¡Œã€‚
            await self._test(ctx)
        elif msg == "æ’¤å›":
            response = f"å·²æ’¤å›ï¼š\n{await config.memory.remove_last_memory()}"
        elif msg == "åˆ—å‡ºå‘½ä»¤":
            response = self._list_commands()
        else:
            need_assistant_reply = True
            need_save_memory = True

        if response:
            await ctx.event.query.adapter.reply_message(ctx.event.query.message_event, platform_message.MessageChain([str(response)]), False)
        return need_assistant_reply, need_save_memory

    def _list_commands(self) -> str:
        return "\n\n".join([f"{cmd}: {desc}" for cmd, desc in COMMANDS.items()])

    def _stop_timer(self, launcher_id: str):
        if launcher_id in self.waifu_cache and self.waifu_cache[launcher_id].launcher_timer_tasks:
            self.waifu_cache[launcher_id].launcher_timer_tasks.cancel()
            self.waifu_cache[launcher_id].launcher_timer_tasks = None
            return "è®¡æ—¶å™¨å·²åœæ­¢ã€‚"
        else:
            return "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„è®¡æ—¶å™¨ã€‚"

    def _ensure_required_files_exist(self):
        directories = ["data/plugins/Waifu/cards", "data/plugins/Waifu/config", "data/plugins/Waifu/data"]

        for directory in directories:
            if not os.path.exists(directory):
                os.makedirs(directory)
                self.ap.logger.info(f"Directory created: {directory}")

        files = ["jail_break_before.txt", "jail_break_after.txt", "jail_break_end.txt", "tidy.py"]
        for file in files:
            file_path = f"data/plugins/Waifu/config/{file}"
            template_path = f"plugins/Waifu/templates/{file}"
            if not os.path.exists(file_path) and os.path.exists(template_path):
                # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¹¶ä¸”æä¾›äº†æ¨¡æ¿ï¼Œåˆ™ä½¿ç”¨æ¨¡æ¿åˆ›å»ºé…ç½®æ–‡ä»¶
                shutil.copyfile(template_path, file_path)

    def _set_permissions_recursively(self, path, mode):
        for root, dirs, files in os.walk(path):
            for dirname in dirs:
                os.chmod(os.path.join(root, dirname), mode)
            for filename in files:
                os.chmod(os.path.join(root, filename), mode)

    async def _request_group_reply(self, ctx: EventContext):
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]
        sender = ctx.event.query.message_event.sender.member_name
        msg = await self._vision(ctx)  # ç”¨çœ¼ç›çœ‹æ¶ˆæ¯ï¼Ÿ
        await config.memory.save_memory(role=sender, content=msg)
        config.unreplied_count += 1
        await self._group_reply(ctx)

    async def _group_reply(self, ctx: EventContext):
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]
        need_assistant_reply = False
        if config.group_message_chain and config.group_message_chain.has(platform_message.At(ctx.event.query.adapter.bot_account_id)):
            need_assistant_reply = True
        if config.unreplied_count >= config.memory.response_min_conversations:
            if random.random() < config.response_rate:
                need_assistant_reply = True
        else:
            self.ap.logger.info(f"ç¾¤èŠ{launcher_id}è¿˜å·®{config.memory.response_min_conversations - config.unreplied_count}æ¡æ¶ˆæ¯è§¦å‘å›å¤")

        config.group_message_chain = None
        if need_assistant_reply:
            if launcher_id not in self.waifu_cache or not config.response_timers_flag:
                config.response_timers_flag = True
                asyncio.create_task(self._delayed_group_reply(ctx))

    async def _delayed_group_reply(self, ctx: EventContext):
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]
        self.ap.logger.info(f"wait group {launcher_id} for {config.group_response_delay}s")
        await asyncio.sleep(config.group_response_delay)
        self.ap.logger.info(f"generating group {launcher_id} response")

        try:
            # è§¦å‘å›å¤åï¼Œé¦–å…ˆæ£€æŸ¥æ˜¯å¦æ»¡è¶³é¢„è®¾å›å¤å½¢å¼ï¼Œé¢„è®¾å›å¤ä¸ç”¨è„‘å­ï¼Œä¸èµ°æ¨¡å‹ã€‚
            response = self._response_presets(launcher_id)
            if response:
                config.unreplied_count = 0
                await config.memory.save_memory(role="assistant", content=response)
                await self._reply(ctx, f"{response}", True)
            else:
                await self._send_group_reply(ctx)

            config.response_timers_flag = False
            await self._group_reply(ctx)  # æ£€æŸ¥æ˜¯å¦å›å¤æœŸé—´åˆæ»¡è¶³å“åº”æ¡ä»¶

        except Exception as e:
            self.ap.logger.error(f"Error occurred during group reply: {e}")
            raise

        finally:
            config.response_timers_flag = False

    async def _send_group_reply(self, ctx: EventContext):
        """
        è°ƒç”¨æ¨¡å‹ç”Ÿæˆç¾¤èŠå›å¤
        """
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]
        if config.summarization_mode:
            _, unreplied_conversations = config.memory.get_unreplied_msg(config.unreplied_count)
            related_memories = await config.memory.load_memory(unreplied_conversations)
            if related_memories:
                config.cards.set_memory(related_memories)
        # å¦‚æœæ˜¯ç¾¤èŠåˆ™ä¸ä¿®æ”¹ä¸ºè‡ªå®šä¹‰è§’è‰²å
        system_prompt = config.memory.to_custom_names(config.cards.generate_system_prompt())
        # å¤‡ä»½ç„¶åé‡ç½®é¿å…å›å¤è¿‡ç¨‹ä¸­æ¥æ”¶åˆ°æ–°è®¯æ¯å¯¼è‡´è®¡æ•°é”™è¯¯
        unreplied_count = config.unreplied_count
        config.unreplied_count = 0
        user_prompt = config.memory.get_normalize_short_term_memory()  # é»˜è®¤ä¸ºå½“å‰short_term_memory_sizeæ¡èŠå¤©è®°å½•
        if config.thinking_mode_flag:
            user_prompt, analysis = await config.thoughts.generate_group_prompt(config.memory, config.cards, unreplied_count)
            if config.display_thinking and config.conversation_analysis_flag:
                await self._reply(ctx, f"ã€åˆ†æã€‘ï¼š{analysis}")
        self._generator.set_speakers([config.memory.assistant_name])
        response = await self._generator.return_chat(user_prompt, system_prompt)
        await config.memory.save_memory(role="assistant", content=response)

        if config.personate_mode:
            await self._send_personate_reply(ctx, response)
        else:
            await self._reply(ctx, f"{response}", True)

    async def _request_person_reply(self, ctx: EventContext, need_save_memory: bool):
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]

        if need_save_memory:  # æ­¤å¤„ä»…å¤„ç†userçš„å‘è¨€ï¼Œä¿å­˜è‡³çŸ­æœŸè®°å¿†
            msg = await self._vision(ctx)  # ç”¨çœ¼ç›çœ‹æ¶ˆæ¯ï¼Ÿ
            await config.memory.save_memory(role="user", content=msg)
        config.unreplied_count += 1
        await self._person_reply(ctx)

    async def _person_reply(self, ctx: EventContext):   #ç§èŠå›å¤
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]


        if config.unreplied_count > 0:
            if launcher_id not in self.waifu_cache or not config.response_timers_flag:
                if self.generator_model_ready:
                    config.response_timers_flag = True
                    asyncio.create_task(self._delayed_person_reply(ctx))  # åˆ›å»ºä»»åŠ¡



    async def _delayed_person_reply(self, ctx: EventContext):
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]
        self.ap.logger.info(f"wait person {launcher_id} for {config.person_response_delay}s")
        await asyncio.sleep(config.person_response_delay)
        self.ap.logger.info(f"generating person {launcher_id} response")

        try:
            config.unreplied_count = 0
            if config.story_mode_flag:
                value_game = config.value_game
                manner = value_game.get_manner_description()
                if manner:
                    config.cards.set_manner(manner)
            if config.summarization_mode:
                _, unreplied_conversations = config.memory.get_unreplied_msg(config.unreplied_count)
                related_memories = await config.memory.load_memory(unreplied_conversations)
                config.cards.set_memory(related_memories)

            # user_promptä¸ç›´æ¥ä»msgç”Ÿæˆï¼Œè€Œæ˜¯å…ˆå°†msgä¿å­˜è‡³çŸ­æœŸè®°å¿†ï¼Œå†ç”±çŸ­æœŸè®°å¿†ç”Ÿæˆã€‚
            # å¥½å¤„æ˜¯ä¸è®ºæ—ç™½æˆ–æ˜¯æ§åˆ¶äººç‰©ï¼Œéƒ½èƒ½ç›´æ¥è°ƒç”¨è®°å¿†ç”Ÿæˆå›å¤
            user_prompt = config.memory.get_normalize_short_term_memory()  # é»˜è®¤ä¸ºå½“å‰short_term_memory_sizeæ¡èŠå¤©è®°å½•
            if config.thinking_mode_flag:
                user_prompt, analysis = await config.thoughts.generate_person_prompt(config.memory, config.cards)
                if config.display_thinking and config.conversation_analysis_flag:
                    await self._reply(ctx, f"ã€åˆ†æã€‘ï¼š{analysis}")
            await self._send_person_reply(ctx, user_prompt)  # ç”Ÿæˆå›å¤å¹¶å‘é€

            if config.story_mode_flag:
                value_game = config.value_game
                await value_game.determine_manner_change(config.memory, config.continued_count)
                if config.display_value:  # æ˜¯å¦å¼€å¯æ•°å€¼æ˜¾ç¤º
                    response = value_game.get_manner_value_str()
                    if response:
                        await self._reply(ctx, f"{response}")
            config.continued_count = 0

            config.response_timers_flag = False
          #  await self._person_reply(ctx)  # æ£€æŸ¥æ˜¯å¦å›å¤æœŸé—´åˆæ»¡è¶³å“åº”æ¡ä»¶

        except Exception as e:
            self.ap.logger.error(f"Error occurred during person reply: {e}")
            raise
        finally:
            config.response_timers_flag = False

    async def _send_person_reply(self, ctx: EventContext, user_prompt: str | list[llm_entities.ContentElement]):
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]
        system_prompt = config.memory.to_custom_names(config.cards.generate_system_prompt())
        self._generator.set_speakers([config.memory.assistant_name])
        response = await self._generator.return_chat(user_prompt, system_prompt)   #å‘æ¶ˆæ¯
        await config.memory.save_memory(role="assistant", content=response)  #å­˜å…¥æ¶ˆæ¯å¯¹è¯

        if config.personate_mode:
            await self._send_personate_reply(ctx, response)
        else:
            await self._reply(ctx, f"{response}", True)

        if random.random() < config.continued_rate and config.continued_count < config.continued_max_count:  # æœºç‡è§¦å‘ç»§ç»­å‘è¨€
            if not config.personate_mode:  # æ‹Ÿäººæ¨¡å¼ä½¿ç”¨é»˜è®¤æ‰“å­—æ—¶é—´ï¼Œéæ‹Ÿäººæ¨¡å¼å–˜å£æ°”
                await asyncio.sleep(1)
            if config.unreplied_count == 0:  # ç”¨æˆ·æœªæ›¾æ‰“æ–­
                config.continued_count += 1
                self.ap.logger.info(f"æ¨¡å‹è§¦å‘ç»§ç»­å›å¤{config.continued_count}æ¬¡")
                await self._continue_person_reply(ctx)

    async def _continue_person_reply(self, ctx: EventContext):
        launcher_id = ctx.event.launcher_id
        config = self.waifu_cache[launcher_id]
        user_prompt = await config.thoughts.generate_person_continue_prompt(config.memory)
        await self._send_person_reply(ctx, user_prompt)  # ç”Ÿæˆå›å¤å¹¶å‘é€

    async def _handle_narration(self, ctx: EventContext, launcher_id: str):
        if launcher_id in self.waifu_cache and self.waifu_cache[launcher_id].launcher_timer_tasks:
            self.waifu_cache[launcher_id].launcher_timer_tasks.cancel()

        self.waifu_cache[launcher_id].launcher_timer_tasks = asyncio.create_task(self._timed_narration_task(ctx, launcher_id))

    async def _timed_narration_task(self, ctx: EventContext, launcher_id: str):
        try:
            config = self.waifu_cache[launcher_id]
            for interval in config.narrate_intervals:
                self.ap.logger.info("Start narrate timer: {}".format(interval))
                await asyncio.create_task(self._sleep_and_narrate(ctx, launcher_id, interval))

            self.ap.logger.info("All intervals completed")
        except asyncio.CancelledError:
            self.ap.logger.info("Narrate timer stoped")
            pass

    async def _sleep_and_narrate(self, ctx: EventContext, launcher_id: str, interval: int):
        await asyncio.sleep(interval)
        await self._narrate(ctx, launcher_id)

    async def _narrate(self, ctx: EventContext, launcher_id: str):
        config = self.waifu_cache[launcher_id]
        conversations = config.memory.short_term_memory
        if len(conversations) < 2:
            return

        narration = await config.narrator.narrate(config.memory, config.cards)
        if narration:
            await self._reply(ctx, f"{config.memory.to_custom_names(narration)}")
            narration = config.memory.to_generic_names(narration)
            await config.memory.save_memory(role="narrator", content=narration)

    async def _send_personate_reply(self, ctx: EventContext, response: str):
        config = self.waifu_cache[ctx.event.launcher_id]
        parts = re.split(r"(?<!\d)[ï¼Œã€‚ï¼Ÿï¼,.?!\n~ã€œ](?!\d)", response)  # ä¿ç•™åˆ†éš”ç¬¦(é¿å…åˆ†å‰²å°æ•°)
        combined_parts = []
        temp_part = ""

        for part in parts:
            part = part.strip()
            if not part:
                continue
            if part in ["ï¼Œ", "ã€‚", ",", ".", "\n"]:  # åˆ é™¤çš„æ ‡ç‚¹ç¬¦å·
                continue
            elif part in ["ï¼Ÿ", "ï¼", "?", "!", "~", "ã€œ"]:  # ä¿ç•™çš„æ ‡ç‚¹ç¬¦å·
                if temp_part or not combined_parts:
                    temp_part += part
                else:
                    combined_parts[-1] += part
            else:
                temp_part += " " + part
                if len(temp_part) >= 3:
                    combined_parts.append(temp_part.strip())
                    temp_part = ""

        if temp_part:  # æ·»åŠ å‰©ä½™éƒ¨åˆ†
            combined_parts.append(temp_part.strip())

        # å¦‚æœresponseæœªä½¿ç”¨åˆ†æ®µæ ‡ç‚¹ç¬¦å·ï¼Œcombined_partsä¸ºç©ºï¼Œæ·»åŠ æ•´ä¸ªresponseä½œä¸ºä¸€ä¸ªå•ç‹¬çš„éƒ¨åˆ†
        if not combined_parts:
            combined_parts.append(response)

        if combined_parts and len(config.bracket_rate) == 2:
            try:
                if random.random() < config.bracket_rate[0]:  # è€äº’è”ç½‘å†²æµªäººå£«äº†ï¼ˆï¼‰
                    combined_parts[-1] += "ï¼ˆï¼‰"
                elif random.random() < config.bracket_rate[1]:
                    combined_parts[-1] += "ï¼ˆ"
            except Exception as e:
                self.ap.logger.error(f"Bracket addition failed: {e}")

        for part in combined_parts:
            await self._reply(ctx, f"{part}", True)
            self.ap.logger.info(f"å‘é€ï¼š{part}")
            if config.personate_delay != 0:
                await asyncio.sleep(config.personate_delay)
            else:
                await asyncio.sleep(len(part) / 2)  # æ ¹æ®å­—æ•°è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼Œå‡è®¾æ¯2ä¸ªå­—ç¬¦1ç§’

    async def _vision(self, ctx: EventContext) -> str:
        # å‚è€ƒè‡ªpreproc.py PreProcessor
        query = ctx.event.query
        has_image = False
        content_list = []

        session = await self.ap.sess_mgr.get_session(query)

        # å°è¯•ä» query.pipeline_config ä¸­è·å– prompt_config
        # å‡è®¾ pipeline é…ç½®ä¸­æœ‰ä¸€ä¸ªåä¸º 'initial_prompt' çš„é”®ï¼Œå…¶å€¼ä¸º list[dict]
        # å¦‚æœæ²¡æœ‰ï¼Œåˆ™ä½¿ç”¨ä¸€ä¸ªç©ºåˆ—è¡¨ä½œä¸ºé»˜è®¤å€¼
        prompt_config_from_pipeline = []
        if query.pipeline_config:
            prompt_config_from_pipeline = query.pipeline_config.get('initial_prompt', [])
            if not isinstance(prompt_config_from_pipeline, list):
                self.ap.logger.warning(f"Pipeline config 'initial_prompt' is not a list, using empty prompt for get_conversation. Found: {prompt_config_from_pipeline}")
                prompt_config_from_pipeline = []
        else:
            self.ap.logger.warning("query.pipeline_config is None, using empty prompt for get_conversation.")

        conversation = await self.ap.sess_mgr.get_conversation(query, session, prompt_config_from_pipeline)

        use_model = conversation.use_llm_model # Changed from conversation.use_model

        for me in query.message_chain:
            if isinstance(me, platform_message.Plain):
                content_list.append(llm_entities.ContentElement.from_text(me.text))
            elif isinstance(me, platform_message.Image):
                if self.ap.instance_config.data["enable-vision"] and use_model:
                    if me.url is not None:
                        has_image = True
                        content_list.append(llm_entities.ContentElement.from_image_url(str(me.url)))
                    elif me.base64 is not None:
                        has_image = True
                        content_list.append(llm_entities.ContentElement.from_image_base64(str(me.base64)))
        if not has_image:
            return str(query.message_chain)
        else:
            return await self.waifu_cache[ctx.event.launcher_id].thoughts.analyze_picture(content_list)

    def _remove_blank_lines(self, text: str) -> str:
        lines = text.split("\n")
        non_blank_lines = [line for line in lines if line.strip() != ""]
        return "\n".join(non_blank_lines)

    async def _reply(self, ctx: EventContext, response: str, event_trigger: bool = False):
        response_fixed = self._remove_blank_lines(response)
        await ctx.event.query.adapter.reply_message(ctx.event.query.message_event, platform_message.MessageChain([f"{response_fixed}"]), False)
        if event_trigger:
            await self._emit_responded_event(ctx, response_fixed)

    async def _emit_responded_event(self, ctx: EventContext, response: str):
        query = ctx.event.query
        session = await self.ap.sess_mgr.get_session(query)
        await self.ap.plugin_mgr.emit_event(
            event=NormalMessageResponded(
                launcher_type=query.launcher_type.value,
                launcher_id=query.launcher_id,
                sender_id=query.sender_id,
                session=session,
                prefix="",
                response_text=response,
                finish_reason="stop",
                funcs_called=[],
                query=query,
            )
        )

    def _response_presets(self, launcher_id: int):
        """
        é¢„è®¾å½¢å¼çš„å›å¤ï¼šå¤è¯»
        """
        response = self._check_repeat(launcher_id)
        return response

    def _check_repeat(self, launcher_id: int) -> str:
        return self.waifu_cache[launcher_id].memory.get_repeat_msg()

    def _set_jail_break(self, cache: WaifuCache, type: str):
        self._generator.set_jail_break(type, cache.memory.user_name)
        cache.memory.set_jail_break(type, cache.memory.user_name)
        cache.value_game.set_jail_break(type, cache.memory.user_name)
        cache.narrator.set_jail_break(type, cache.memory.user_name)
        cache.thoughts.set_jail_break(type, cache.memory.user_name)

    async def _test(self, ctx: EventContext):
        # ä¿å­˜å½“å‰é…ç½®çŠ¶æ€
        original_config = WaifuCache(self.ap, ctx.event.launcher_id, ctx.event.launcher_type)
        current_cache = self.waifu_cache.get(ctx.event.launcher_id)
        if current_cache:
            # æ·±æ‹·è´å¯å˜å¯¹è±¡ï¼Œå¦‚åˆ—è¡¨å’Œå­—å…¸
            for attr, value in vars(current_cache).items():
                if isinstance(value, (list, dict)):
                    setattr(original_config, attr, copy.deepcopy(value))
                else:
                    setattr(original_config, attr, value)

        config = self.waifu_cache[ctx.event.launcher_id]
        config.langbot_group_rule = True
        await self._test_command(ctx, "æµ‹è¯•ç¾¤èŠè§„åˆ™#ä½ å¥½")
        config.langbot_group_rule = False
        await self._test_command(ctx, "æµ‹è¯•ç¾¤èŠè§„åˆ™#ä½ å¥½")
        config.narrate_intervals = [3,5]
        await self._test_command(ctx, "æµ‹è¯•æ—ç™½#ä½ å¥½")
        config.story_mode_flag = False
        await self._test_command(ctx, "å…³é—­æ•…äº‹æ¨¡å¼#ä½ å¥½")
        config.story_mode_flag = True
        await self._test_command(ctx, "å¼€å¯æ•…äº‹æ¨¡å¼#ä½ å¥½")
        config.thinking_mode_flag = False
        await self._test_command(ctx, "å…³é—­æ€è€ƒæ¨¡å¼#ä½ å¥½")
        config.thinking_mode_flag = True
        await self._test_command(ctx, "å¼€å¯æ€è€ƒæ¨¡å¼#ä½ å¥½")
        config.conversation_analysis_flag = False
        await self._test_command(ctx, "å…³é—­ä¼šè¯åˆ†æ#ä½ å¥½")
        config.conversation_analysis_flag = True
        await self._test_command(ctx, "å¼€å¯ä¼šè¯åˆ†æ#ä½ å¥½")
        config.display_thinking = False
        await self._test_command(ctx, "å…³é—­æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹#ä½ å¥½")
        config.display_thinking = True
        await self._test_command(ctx, "å¼€å¯æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹#ä½ å¥½")
        config.display_value = False
        await self._test_command(ctx, "å…³é—­æ˜¾ç¤ºæ•°å€¼#ä½ å¥½")
        config.display_value = True
        await self._test_command(ctx, "å¼€å¯æ˜¾ç¤ºæ•°å€¼#ä½ å¥½")
        config.response_rate = 0
        await self._test_command(ctx, "å…³é—­å›å¤#ä½ å¥½")
        config.response_rate = 1
        await self._test_command(ctx, "å¼€å¯å›å¤#ä½ å¥½")
        config.summarization_mode = False
        await self._test_command(ctx, "å…³é—­æ€»ç»“æ¨¡å¼#ä½ å¥½")
        config.summarization_mode = True
        await self._test_command(ctx, "å¼€å¯æ€»ç»“æ¨¡å¼#ä½ å¥½")
        config.personate_mode = False
        await self._test_command(ctx, "å…³é—­æ‹Ÿäººæ¨¡å¼#ä½ å¥½")
        config.personate_mode = True
        await self._test_command(ctx, "å¼€å¯æ‹Ÿäººæ¨¡å¼#ä½ å¥½")
        config.jail_break_mode = "all"
        self._set_jail_break(config, config.jail_break_mode)
        await self._test_command(ctx, "æ‰‹åŠ¨ä¹¦å†™â€œæŒ‡å®šè§’è‰²â€å‘è¨€#æ§åˆ¶äººç‰©å¿«é€’å‘˜|å®å’š~æœ‰äººåœ¨å®¶å—ï¼Œæœ‰ä½ ä»¬çš„å¿«é€’ï¼")
        config.jail_break_mode = "off"
        self._set_jail_break(config, "off")
        config.personate_delay = 3
        await self._test_command(ctx, "ä¸»åŠ¨è§¦å‘æ—ç™½æ¨è¿›å‰§æƒ…#æ—ç™½")
        config.personate_delay = 0
        config.continued_rate = 1
        config.continued_max_count = 2
        await self._test_command(ctx, "è¯·AIç”Ÿæˆâ€œæŒ‡å®šè§’è‰²â€å‘è¨€#æ§åˆ¶äººç‰©å¿«é€’å‘˜|ç»§ç»­")
        config.continued_rate = 0
        config.continued_max_count = 0
        await self._test_command(ctx, "ä½¿ç”¨â€œæŒ‡å®šè§’è‰²â€æ¨è¿›å‰§æƒ…#æ¨è¿›å‰§æƒ…")
        await self._test_command(ctx, "åœæ­¢æ—ç™½è®¡æ—¶å™¨#åœæ­¢æ´»åŠ¨")
        await self._test_command(ctx, "æŸ¥çœ‹å½“å‰æ€åº¦æ•°å€¼åŠå½“å‰è¡Œä¸ºå‡†åˆ™ï¼ˆMannerï¼‰#æ€åº¦")
        await self._test_command(ctx, "æ›´æ”¹æ€åº¦æ•°å€¼#ä¿®æ”¹æ•°å€¼5")
        await self._test_command(ctx, "åˆ é™¤æ‰€æœ‰è®°å¿†#åˆ é™¤è®°å¿†")
        await self._test_command(ctx, "æ˜¾ç¤ºæœ€è¿‘çš„é•¿æœŸè®°å¿†#æœ€è¿‘è®°å¿†")
        await self._test_command(ctx, "æ˜¾ç¤ºæœ€è¿‘å¬å›çš„è®°å¿†#æœ€è¿‘å¬å›")
        await self._test_command(ctx, "åˆ—å‡ºç›®å‰æ”¯æ´æ‰€æœ‰å‘½ä»¤#åˆ—å‡ºå‘½ä»¤")
        # æ¢å¤åŸå§‹é…ç½®
        for attr, value in vars(original_config).items():
            if hasattr(self.waifu_cache[ctx.event.launcher_id], attr):
                setattr(self.waifu_cache[ctx.event.launcher_id], attr, value)

        # ç‰¹åˆ«å¤„ç†éœ€è¦é‡æ–°è®¾ç½®çš„å±æ€§
        self._set_jail_break(self.waifu_cache[ctx.event.launcher_id], original_config.jail_break_mode)
        if original_config.narrate_intervals:
            asyncio.create_task(self._handle_narration(ctx, ctx.event.launcher_id))
        else:
            self._stop_timer(ctx.event.launcher_id)

        await ctx.reply(platform_message.MessageChain([platform_message.Plain("æµ‹è¯•å®Œæˆï¼Œå·²æ¢å¤é…ç½®ã€‚")]))

    async def _test_command(self, ctx: EventContext, command: str):
        parts = command.split("#")
        if len(parts) == 2:
            note = parts[0].strip()
            cmd = parts[1].strip()
        await self._reply(ctx, f"ã€æ¨¡æ‹Ÿå‘é€ã€‘ï¼ˆ{note}ï¼‰\n{cmd}")
        ctx.event.query.message_chain = platform_message.MessageChain([cmd])
        need_assistant_reply, need_save_memory = await self._handle_command(ctx)
        if need_assistant_reply:
            if need_save_memory:
                msg = await self._vision(ctx)
                await self.waifu_cache[ctx.event.launcher_id].memory.save_memory(role="user", content=msg)
            await self._delayed_person_reply(ctx)

    def __del__(self):
        for config in self.waifu_cache.values():
            if config.launcher_timer_tasks:
                config.launcher_timer_tasks.cancel()




    def _load_target_qq_from_global_config_file(self,file_path: str) -> typing.Optional[str]:  #åŠ è½½plugins/Waifu/templates/waifu.yaml é‡Œé…ç½®çš„qqå·

        if not os.path.exists(file_path):
            print(f"ERROR: file not found: {file_path}\\n")
            return None

        config_data: typing.Optional[dict] = None
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                config_data = yaml.safe_load(f)
        except yaml.YAMLError as ye:
            print(f"ERROR: YAML parsing error in {file_path}: {ye}\\n")
            return None
        except IOError as ioe:
            print(f"ERROR: Could not read file {file_path}: {ioe}\\n")
            return None
        except Exception as e_file:
            print(f"ERROR: Unexpected error opening/reading file {file_path}: {e_file}\\n")
            traceback.print_exc()
            return None

        if not config_data or not isinstance(config_data, dict):
            print(f"ERROR: file {file_path} is empty or not a valid YAML dictionary after loading.\\n")
            return None

        target_qq_from_config = config_data.get("target_user_id")  #è·å–qqå·

        if target_qq_from_config and isinstance(target_qq_from_config, str) and target_qq_from_config.strip():

            cleaned_target_qq = target_qq_from_config.strip()
            print(f"Successfully loaded default_proactive_target_qq: {cleaned_target_qq}")
            return cleaned_target_qq
        else:
            print(
                f"ERROR: 'target_qq' not found, or is empty in {file_path}. Value was: '{target_qq_from_config}'\\n")
            return None
